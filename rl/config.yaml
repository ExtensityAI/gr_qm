
# ======================
# Hydra + PPO config
# ======================
defaults:
  - _self_

seed: 42
device: auto
n_envs: 4

# --------- Environment ---------
env:
  core_model: fractional       # fractional | absolute
  eps_min: 0.0
  eps_max: 0.15
  L0_min: 0.0
  L0_max: 0.6
  max_steps: 64
  chi2_converged: 1e-6
  step_size: 0.02
  use_loglike_reward: true
  render_width: 256
  render_height: 144
  render_device: cpu
  enable_render_overlays: false
  init_center_eps: 0.05
  init_spread: 0.03
  default_M_solar: 70.0
  # Difficulty mode and extensions
  difficulty: LOW          # LOW | MEDIUM | HARD
  fidelity_low_noise_mult: 1.0
  fidelity_high_noise_mult: 0.25
  fidelity_low_step_cost: 0.0
  fidelity_high_step_cost: 1.0
  budget_init: 10.0
  cost_weight: 0.05
  cost_query_f220: 1.0
  cost_query_tau220: 1.0
  cost_query_theta: 2.0
  cost_query_bc: 1.5
  hard_terminal_full_eval: true
  include_masks_in_obs: true
  hard_noise_scale: 1.0

# --------- Targets (example ringdown-only; set your data here) ---------
target:
  f220_Hz: null          # e.g., 250.1
  sigma_f_Hz: null       # e.g., 0.5
  tau220_s: null         # e.g., 0.004
  sigma_tau_s: null      # e.g., 0.001
  M_solar: 70.0
  distance_m: null
  theta_shadow_rad: null
  sigma_theta_rad: null
  b_c_m: null
  sigma_b_c_m: null

# --------- PPO hyperparameters ---------
ppo:
  policy: MlpPolicy
  learning_rate: 3.0e-4
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.995
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.0
  vf_coef: 0.5
  max_grad_norm: 0.5
  net_arch: [256, 256]

# --------- Training control ---------
train:
  total_timesteps: 250000
  progress_bar: true

# --------- Evaluation ---------
eval:
  eval_freq: 10000
  n_episodes: 10

# --------- VecNormalize ---------
vecnormalize:
  enabled: true
  norm_obs: true
  norm_reward: false
  clip_obs: 10.0
  gamma: 0.995

# --------- Logging / Artifacts ---------
logging:
  tensorboard_dir: outputs   # TensorBoard logs under repo outputs/
  monitor_dir: monitors
  checkpoint_dir: checkpoints
  best_model_dir: best
  eval_log_dir: eval_logs
  model_dir: models

# --------- Checkpointing ---------
checkpoint:
  enabled: true
  save_freq: 50000
  name_prefix: "ppo_blackhole"

# --------- Difficulty Presets ---------
difficulty_profile: null     # null | medium | hard
difficulty_presets:
  medium:
    env:
      difficulty: MEDIUM
      cost_weight: 0.05
      fidelity_high_step_cost: 1.0
      fidelity_low_step_cost: 0.0
      fidelity_low_noise_mult: 1.0
      fidelity_high_noise_mult: 0.25
      include_masks_in_obs: true
    ppo:
      ent_coef: 0.01
      n_steps: 2048
      batch_size: 64
  hard:
    env:
      difficulty: HARD
      budget_init: 10.0
      cost_weight: 0.05
      fidelity_high_step_cost: 1.0
      fidelity_low_step_cost: 0.0
      include_masks_in_obs: true
      hard_terminal_full_eval: true
      hard_noise_scale: 1.0
    ppo:
      ent_coef: 0.02
      n_steps: 4096
      batch_size: 64
